
# FPGA-Based Real-Time Edge AI Vision Classification System

## ğŸ“Œ Project Overview

This project implements a hardware-accelerated Convolutional Neural Network (CNN) for real-time image classification using FPGA.  

The CNN model is trained in PyTorch, quantized to fixed-point format, and implemented in Verilog RTL for FPGA synthesis and timing analysis using Vivado.

The system demonstrates hardware-software co-design by mapping a trained neural network into a synthesizable FPGA architecture.

---

## ğŸ¯ Objectives

- Train a CNN model in PyTorch
- Convert floating-point weights to fixed-point (Q8.8 format)
- Export quantized weights for hardware usage
- Implement convolution, ReLU, and fully connected layers in Verilog
- Load trained weights into FPGA using on-chip ROM
- Perform functional simulation in Vivado
- Analyze timing closure and resource utilization
- Compute latency and throughput metrics

---

## ğŸ§  CNN Architecture

### Software Model (PyTorch)

Conv2D (3x3, 1 filter)  
â†’ ReLU  
â†’ Flatten  
â†’ Fully Connected  
â†’ Classification Output  

### Hardware Architecture (FPGA RTL)

3Ã—3 Convolution (9 DSP multipliers)  
â†’ ReLU (Comparator logic)  
â†’ Sequential MAC-based Fully Connected Layer  
â†’ Final Output Score  

All modules are fully synchronous (clocked) and reset-controlled.

---

## âš™ï¸ Implementation Details

### 1ï¸âƒ£ Model Training (Kaggle â€“ PyTorch)

- Dataset: MNIST
- Framework: PyTorch
- Quantization: 16-bit Fixed-Point (Q8.8)
- Weights exported to `.mem` format for FPGA

### 2ï¸âƒ£ Fixed-Point Representation

- Data width: 16-bit signed
- Scale factor: 2^8 = 256
- Arithmetic implemented using signed multipliers

---

## ğŸ§± FPGA Modules

- `conv3x3.v` â†’ Registered 3Ã—3 convolution engine
- `relu.v` â†’ Clocked ReLU activation
- `fc_layer.v` â†’ Sequential MAC-based fully connected layer
- `top_module.v` â†’ Complete CNN pipeline
- `testbench.v` â†’ Functional verification
- `constraints.xdc` â†’ Clock constraint (100 MHz)

Weights are stored in ROM and loaded via `$readmemh`.

---

## ğŸ§ª Functional Verification

Vivado Behavioral Simulation verifies:

- Correct convolution output
- Correct ReLU behavior
- Correct FC accumulation
- RTL output matches PyTorch fixed-point inference

---

## ğŸ“Š Synthesis & Timing Analysis

Target Device: Xilinx Artix-7  

Measured Metrics:
- LUT utilization
- Flip-flop usage
- DSP slice usage
- Timing closure (WNS)
- Maximum operating frequency (Fmax)

---
Clock Constraint:
create_clock -period 10.000 -name clk [get_ports clk]


---

## ğŸš€ Performance Evaluation

Latency = (Pipeline cycles + FC cycles) / Fmax  

Example (100 MHz clock):
- Total cycles â‰ˆ 678
- Latency â‰ˆ 6â€“7 Âµs
- Throughput â‰ˆ 100M operations/sec

---

## ğŸ— Design Characteristics

âœ” Fully synchronous design  
âœ” Clock + Reset controlled  
âœ” Fixed-point arithmetic  
âœ” DSP-based multiplication  
âœ” Synthesizable RTL  
âœ” Timing-closure verified  
âœ” Hardware-software co-design  

---

## ğŸ“ Project Structure

---

## ğŸš€ Performance Evaluation

Latency = (Pipeline cycles + FC cycles) / Fmax  

Example (100 MHz clock):
- Total cycles â‰ˆ 678
- Latency â‰ˆ 6â€“7 Âµs
- Throughput â‰ˆ 100M operations/sec

---

## ğŸ— Design Characteristics

âœ” Fully synchronous design  
âœ” Clock + Reset controlled  
âœ” Fixed-point arithmetic  
âœ” DSP-based multiplication  
âœ” Synthesizable RTL  
âœ” Timing-closure verified  
âœ” Hardware-software co-design  

---

## ğŸ“ Project Structure
â”œâ”€â”€ conv3x3.v
â”œâ”€â”€ relu.v
â”œâ”€â”€ fc_layer.v
â”œâ”€â”€ top_module.v
â”œâ”€â”€ testbench.v
â”œâ”€â”€ constraints.xdc
â”œâ”€â”€ conv_weights.mem
â”œâ”€â”€ fc_weights.mem
â””â”€â”€ README.md


---

## ğŸ’¡ Key Learnings

- Mapping neural networks to hardware
- Fixed-point quantization tradeoffs
- DSP slice utilization in FPGA
- Timing constraint management
- Resource-performance tradeoff analysis
- Hardware validation of ML models

---
## Hardware Results

- Maximum Frequency: ~126 MHz
- Slice LUTs Used: 129 (0.39%)
- Registers Used: 81 (0.12%)
- DSP48 Used: 11 (9%)
- Timing Constraints: Met
- Inference Latency: ~87 ns (for demo input size)

---  

## ğŸ”® Future Improvements

- Multi-filter convolution support
- Parallel fully connected units
- BRAM-based weight storage
- Streaming line-buffer architecture
- AXI interface integration
- Real-time camera input support

---

## ğŸ“Œ Conclusion

This project demonstrates the end-to-end deployment of a trained CNN model onto FPGA hardware using fixed-point arithmetic and RTL design.  

It highlights performance analysis, timing closure, and hardware acceleration techniques relevant for edge AI and FPGA-based ML systems.

---

## ğŸ‘¨â€ğŸ’» Author

Sharath Chandra  
FPGA & AI/ML Enthusiast  
